#!/usr/bin/env ruby

require 'yaml'
require 'open3'
require 'json'
require 'net/http'

def verify_requirements
    ['aws', 'terraform', 'ansible'].each do |cmd|
        if !cmd_exists?(cmd)
            raise "Missing required command #{cmd}. Check requirements on documentation."
        end
    end
end

# TODO
def verify_deployment(infra, opsforge_template)
    # Check engine port reachable
    # Check Sunstone port reachable
    # Check FireEdge port reachable
    # Check engine -> oned
    # Check engine -> oneflow
end

# TODO: create a schema for opsforge template and validate it
def validate_template(opsforge_template); end

def terraform_aws(opsforge_template)
    puts 'Setting up infrastructure on AWS'

    ec2_instances = {
        :frontend => nil,
        :engine => nil
    }

    tfvars = "#{__dir__}/terraform/aws/terraform.tfvars"
    File.new(tfvars, 'w') unless File.exist?(tfvars)

    File.open(tfvars, 'w') do |file|
        file.puts("local_machine_ip = \"#{public_ip}\"")

        opsforge_template.each do |infra, conf|
            conf.each do |setting, value|
                file.puts("#{infra}_#{setting} = \"#{value}\"")
            end
        end
    end

    infra = JSON.parse(terraform('aws').last)

    ['frontend', 'engine'].each do |ec2|
        ec2_instances[ec2.to_sym] = infra[ec2]['value']
    end

    puts 'Infrastructure on AWS has been deployed'

    return ec2_instances
end

# TODO: Sunstone port
# TODO: FireEdge port
# TODO: Engine port
# TODO: baremetal deployment
def ansible(infra, opsforge_template)
    puts 'Installing Frontend and Provisioning Engine'

    inventory = {
        'frontend' => {
            'hosts' => {
                'f1' => {
                    'ansible_host' => infra[:frontend]
                }
            },
            'vars' => {
                'one_version' => opsforge_template[:one][:version],
                'one_pass' => opsforge_template[:one][:password],
                'features' => {
                    'prometheus' => false,
                    'gateproxy' => false
                },
                'vn' => {
                    'admin_net' => {
                        'managed' => true,
                        'template' => {
                            'VN_MAD' => 'bridge',
                        'PHYDEV' => 'eth0',
                        'BRIDGE' => 'br0',
                        'AR' => {
                            'TYPE' => 'IP4',
                            'IP' => '172.20.0.100',
                            'SIZE' => 48,
                            'NETWORK_ADDRESS' => '172.20.0.0',
                            'NETWORK_MASK' => '255.255.255.0',
                            'GATEWAY' => '172.20.0.1',
                            'DNS' => '1.1.1.1'
                        }
                        }
                    }
                }
            }
        },
        'engine' => {
            'hosts' => {
                'e1' => {
                    'ansible_host' => infra[:engine]
                }
            },
            'vars' => {
                'oned' => "http://#{infra[:frontend]}:2633/RPC2",
                'oneflow' => "http://#{infra[:frontend]}:2474"
            }
        }
    }

    if opsforge_template[:one][:ee_token]
        inventory['frontend']['vars']['one_token'] = opsforge_template[:one][:ee_token]
        inventory['frontend']['vars']['features']['prometheus'] = true
    end

    inventory = inventory.to_yaml

    cfg = <<~EOT
        [defaults]
        collections_paths=./one-deploy/ansible_collections/
        inventory=./inventory.yaml
        gathering=explicit
        host_key_checking=false
        display_skipped_hosts=true
        retry_files_enabled=false
        any_errors_fatal=true
        stdout_callback=yaml
        timeout=30
        private_key_file = #{opsforge_template[:aws][:ssh_key_path]}
        remote_user = ubuntu

        [privilege_escalation]
        become=true
        become_user=root

        [ssh_connection]
        pipelining=true
        ssh_args=-q -o ControlMaster=auto -o ControlPersist=60

    EOT

    Dir.chdir("#{__dir__}/ansible/one-deploy")
    cmd_exec('make requirements')
    Dir.chdir("#{__dir__}/ansible")

    File.write("#{__dir__}/ansible/inventory.yaml", inventory)
    File.write("#{__dir__}/ansible/ansible.cfg", cfg)

    30.times do |t|
        raise 'Timeout while waiting for SSH access to AWS infra' if t == 30

        begin
            cmd_exec("ssh ubuntu@#{infra[:frontend]} uptime", false)
        rescue StandardError
            sleep 1
            next
        end
    end

    cmd_exec('ansible-playbook playbooks/cognit.yaml')
    Dir.chdir("#{__dir__}/..")

    puts 'Frontend and Provisioning Engine installed'
end

def terraform_opennebula(frontend, opsforge_template)
    puts 'Setting up Frontend for Cognit'

    tfvars = "#{__dir__}/terraform/opennebula/terraform.tfvars"
    File.new(tfvars, 'w') unless File.exist?(tfvars)

    oned = "http://#{frontend}:2633/RPC2"
    oneflow = "http://#{frontend}:2474"

    File.open(tfvars, 'w') do |file|
        file.puts("oned = \"#{oned}\"")
        file.puts("oneflow = \"#{oneflow}\"")
        file.puts("password = \"#{opsforge_template[:one][:password]}\"")
    end

    terraform('opennebula')

    puts 'Frontend ready for Cognit'
end

def clean
    ['opennebula', 'aws'].each do |provider|
        Dir.chdir("#{__dir__}/terraform/#{provider}")
        cmd_exec('terraform destroy --auto-approve', false)
    end

    ['ansible.cfg', 'inventory.yaml'].each do |file|
        File.delete("#{__dir__}/ansible/#{file}")
    end

    File.delete("#{__dir__}/opsforge.log")
end

# Helpers

def cmd_exec(cmd, log = true)
    o, e, s = Open3.capture3(cmd)

    if s != 0
        STDERR.puts "Command \"#{cmd}\" failed:"
        raise "#{o}\n#{e}"
    end

    log(o) if log

    o
end

def cmd_exists?(command)
    exts = ENV['PATHEXT'] ? ENV['PATHEXT'].split(';') : ['']
    ENV['PATH'].split(File::PATH_SEPARATOR).each do |path|
        exts.each do |ext|
            exe = File.join(path, "#{command}#{ext}")
            return true if File.executable?(exe) && !File.directory?(exe)
        end
    end
    false
end

def terraform(provider)
    output = []

    Dir.chdir("#{__dir__}/terraform/#{provider}")

    ['terraform init', 'terraform apply --auto-approve', 'terraform output -json'].each do |cmd|
        output << cmd_exec(cmd)
    end

    Dir.chdir(__dir__)

    output
end

def public_ip
    uri = URI('https://api.ipify.org')
    response = Net::HTTP.get(uri)
    response.strip
end

def log(info)
    file = "#{__dir__}/opsforge.log"
    File.open(file, 'a') do |f|
        f.puts info
    end
end

# BEGIN

verify_requirements

case ARGV[0]
when 'deploy'
    # TODO: Add timer for each stage
    opsforge_template = YAML.load_file(ARGV[1])
    validate_template(opsforge_template)

    infra = terraform_aws(opsforge_template)
    ansible(infra, opsforge_template)
    terraform_opennebula(infra[:frontend], opsforge_template)

    verify_deployment(infra, opsforge_template)

    puts infra
    puts 'Logs available at ./opsforge.log'
    puts "Take a look at AWS cluster provisioning in order to setup your KVM cluster\nhttps://docs.opennebula.io/6.8/provision_clusters/providers/aws_provider.html#aws-provider"
when 'clean'
    clean
else
    STDERR.puts 'invalid command'
    exit 1
end
